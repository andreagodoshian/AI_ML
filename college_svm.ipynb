{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DESCRIPTION\n",
    "\n",
    "Load the data from “college.csv” that has attributes collected about private and public colleges for a particular year. Predict the private/public status of the colleges from other attributes. Use LabelEncoder to encode the target variable to numerical form. Split the data such that 20% of the data is set aside for testing. Fit a linear SVM from scikit-learn and observe the accuracy. [Hint: Use Linear SVC] Preprocess the data using StandardScalar and fit the same model again. Observe the change in accuracy.  Use scikit-learn’s gridsearch to select the best hyper-parameter for a non-linear SVM. Identify the model with the best score and its parameters. [Hint: Refer to model_selection module of Scikit learn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 777 entries, 0 to 776\n",
      "Data columns (total 18 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Private      777 non-null    object \n",
      " 1   Apps         777 non-null    int64  \n",
      " 2   Accept       777 non-null    int64  \n",
      " 3   Enroll       777 non-null    int64  \n",
      " 4   Top10perc    777 non-null    int64  \n",
      " 5   Top25perc    777 non-null    int64  \n",
      " 6   F.Undergrad  777 non-null    int64  \n",
      " 7   P.Undergrad  777 non-null    int64  \n",
      " 8   Outstate     777 non-null    int64  \n",
      " 9   Room.Board   777 non-null    int64  \n",
      " 10  Books        777 non-null    int64  \n",
      " 11  Personal     777 non-null    int64  \n",
      " 12  PhD          777 non-null    int64  \n",
      " 13  Terminal     777 non-null    int64  \n",
      " 14  S.F.Ratio    777 non-null    float64\n",
      " 15  perc.alumni  777 non-null    int64  \n",
      " 16  Expend       777 non-null    int64  \n",
      " 17  Grad.Rate    777 non-null    int64  \n",
      "dtypes: float64(1), int64(16), object(1)\n",
      "memory usage: 109.4+ KB\n"
     ]
    }
   ],
   "source": [
    "the_path = r\"C:\\Users\\12489\\Documents\\Data\\College.csv\"\n",
    "df = pd.read_csv(the_path)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>777.000000</td>\n",
       "      <td>777.000000</td>\n",
       "      <td>777.000000</td>\n",
       "      <td>777.000000</td>\n",
       "      <td>777.000000</td>\n",
       "      <td>777.000000</td>\n",
       "      <td>777.000000</td>\n",
       "      <td>777.000000</td>\n",
       "      <td>777.000000</td>\n",
       "      <td>777.000000</td>\n",
       "      <td>777.000000</td>\n",
       "      <td>777.000000</td>\n",
       "      <td>777.000000</td>\n",
       "      <td>777.000000</td>\n",
       "      <td>777.000000</td>\n",
       "      <td>777.000000</td>\n",
       "      <td>777.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3001.638353</td>\n",
       "      <td>2018.804376</td>\n",
       "      <td>779.972973</td>\n",
       "      <td>27.558559</td>\n",
       "      <td>55.796654</td>\n",
       "      <td>3699.907336</td>\n",
       "      <td>855.298584</td>\n",
       "      <td>10440.669241</td>\n",
       "      <td>4357.526384</td>\n",
       "      <td>549.380952</td>\n",
       "      <td>1340.642214</td>\n",
       "      <td>72.660232</td>\n",
       "      <td>79.702703</td>\n",
       "      <td>14.089704</td>\n",
       "      <td>22.743887</td>\n",
       "      <td>9660.171171</td>\n",
       "      <td>65.46332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3870.201484</td>\n",
       "      <td>2451.113971</td>\n",
       "      <td>929.176190</td>\n",
       "      <td>17.640364</td>\n",
       "      <td>19.804778</td>\n",
       "      <td>4850.420531</td>\n",
       "      <td>1522.431887</td>\n",
       "      <td>4023.016484</td>\n",
       "      <td>1096.696416</td>\n",
       "      <td>165.105360</td>\n",
       "      <td>677.071454</td>\n",
       "      <td>16.328155</td>\n",
       "      <td>14.722359</td>\n",
       "      <td>3.958349</td>\n",
       "      <td>12.391801</td>\n",
       "      <td>5221.768440</td>\n",
       "      <td>17.17771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>1780.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3186.000000</td>\n",
       "      <td>10.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>776.000000</td>\n",
       "      <td>604.000000</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>992.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>7320.000000</td>\n",
       "      <td>3597.000000</td>\n",
       "      <td>470.000000</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6751.000000</td>\n",
       "      <td>53.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1558.000000</td>\n",
       "      <td>1110.000000</td>\n",
       "      <td>434.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>1707.000000</td>\n",
       "      <td>353.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>4200.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>8377.000000</td>\n",
       "      <td>65.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3624.000000</td>\n",
       "      <td>2424.000000</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>4005.000000</td>\n",
       "      <td>967.000000</td>\n",
       "      <td>12925.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>1700.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>10830.000000</td>\n",
       "      <td>78.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>48094.000000</td>\n",
       "      <td>26330.000000</td>\n",
       "      <td>6392.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>31643.000000</td>\n",
       "      <td>21836.000000</td>\n",
       "      <td>21700.000000</td>\n",
       "      <td>8124.000000</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>6800.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>39.800000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>56233.000000</td>\n",
       "      <td>118.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Apps        Accept       Enroll   Top10perc   Top25perc  \\\n",
       "count    777.000000    777.000000   777.000000  777.000000  777.000000   \n",
       "mean    3001.638353   2018.804376   779.972973   27.558559   55.796654   \n",
       "std     3870.201484   2451.113971   929.176190   17.640364   19.804778   \n",
       "min       81.000000     72.000000    35.000000    1.000000    9.000000   \n",
       "25%      776.000000    604.000000   242.000000   15.000000   41.000000   \n",
       "50%     1558.000000   1110.000000   434.000000   23.000000   54.000000   \n",
       "75%     3624.000000   2424.000000   902.000000   35.000000   69.000000   \n",
       "max    48094.000000  26330.000000  6392.000000   96.000000  100.000000   \n",
       "\n",
       "        F.Undergrad   P.Undergrad      Outstate   Room.Board        Books  \\\n",
       "count    777.000000    777.000000    777.000000   777.000000   777.000000   \n",
       "mean    3699.907336    855.298584  10440.669241  4357.526384   549.380952   \n",
       "std     4850.420531   1522.431887   4023.016484  1096.696416   165.105360   \n",
       "min      139.000000      1.000000   2340.000000  1780.000000    96.000000   \n",
       "25%      992.000000     95.000000   7320.000000  3597.000000   470.000000   \n",
       "50%     1707.000000    353.000000   9990.000000  4200.000000   500.000000   \n",
       "75%     4005.000000    967.000000  12925.000000  5050.000000   600.000000   \n",
       "max    31643.000000  21836.000000  21700.000000  8124.000000  2340.000000   \n",
       "\n",
       "          Personal         PhD    Terminal   S.F.Ratio  perc.alumni  \\\n",
       "count   777.000000  777.000000  777.000000  777.000000   777.000000   \n",
       "mean   1340.642214   72.660232   79.702703   14.089704    22.743887   \n",
       "std     677.071454   16.328155   14.722359    3.958349    12.391801   \n",
       "min     250.000000    8.000000   24.000000    2.500000     0.000000   \n",
       "25%     850.000000   62.000000   71.000000   11.500000    13.000000   \n",
       "50%    1200.000000   75.000000   82.000000   13.600000    21.000000   \n",
       "75%    1700.000000   85.000000   92.000000   16.500000    31.000000   \n",
       "max    6800.000000  103.000000  100.000000   39.800000    64.000000   \n",
       "\n",
       "             Expend  Grad.Rate  \n",
       "count    777.000000  777.00000  \n",
       "mean    9660.171171   65.46332  \n",
       "std     5221.768440   17.17771  \n",
       "min     3186.000000   10.00000  \n",
       "25%     6751.000000   53.00000  \n",
       "50%     8377.000000   65.00000  \n",
       "75%    10830.000000   78.00000  \n",
       "max    56233.000000  118.00000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Private        0\n",
       "Apps           0\n",
       "Accept         0\n",
       "Enroll         0\n",
       "Top10perc      0\n",
       "Top25perc      0\n",
       "F.Undergrad    0\n",
       "P.Undergrad    0\n",
       "Outstate       0\n",
       "Room.Board     0\n",
       "Books          0\n",
       "Personal       0\n",
       "PhD            0\n",
       "Terminal       0\n",
       "S.F.Ratio      0\n",
       "perc.alumni    0\n",
       "Expend         0\n",
       "Grad.Rate      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'No'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Private'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (777, 18)\n",
      "Total number of labels 777\n",
      "\n",
      "Total number of 'Yes' for Private College: 565\n",
      "Total number of 'No' for Private College: 212\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"Shape of data: {df.shape}\n",
    "Total number of labels {df.shape[0]}\n",
    "\n",
    "Total number of 'Yes' for Private College: {df[df.Private=='Yes'].shape[0]}\n",
    "Total number of 'No' for Private College: {df[df.Private=='No'].shape[0]}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Yes\n",
       "1      Yes\n",
       "2      Yes\n",
       "3      Yes\n",
       "4      Yes\n",
       "      ... \n",
       "772     No\n",
       "773    Yes\n",
       "774    Yes\n",
       "775    Yes\n",
       "776    Yes\n",
       "Name: Private, Length: 777, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.iloc[:,0]\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since the only non-numeric column is the label (y),\n",
    "# we only need to encode that\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# great, now make sure it worked...\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### after examination, \"1 = Yes\" and \"0 = No\"\n",
    "\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>2197</td>\n",
       "      <td>1515</td>\n",
       "      <td>543</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>3089</td>\n",
       "      <td>2029</td>\n",
       "      <td>6797</td>\n",
       "      <td>3900</td>\n",
       "      <td>500</td>\n",
       "      <td>1200</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14</td>\n",
       "      <td>4469</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>1959</td>\n",
       "      <td>1805</td>\n",
       "      <td>695</td>\n",
       "      <td>24</td>\n",
       "      <td>47</td>\n",
       "      <td>2849</td>\n",
       "      <td>1107</td>\n",
       "      <td>11520</td>\n",
       "      <td>4960</td>\n",
       "      <td>600</td>\n",
       "      <td>1250</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>13.3</td>\n",
       "      <td>31</td>\n",
       "      <td>9189</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>2097</td>\n",
       "      <td>1915</td>\n",
       "      <td>695</td>\n",
       "      <td>34</td>\n",
       "      <td>61</td>\n",
       "      <td>2793</td>\n",
       "      <td>166</td>\n",
       "      <td>6900</td>\n",
       "      <td>4200</td>\n",
       "      <td>617</td>\n",
       "      <td>781</td>\n",
       "      <td>67</td>\n",
       "      <td>75</td>\n",
       "      <td>14.4</td>\n",
       "      <td>20</td>\n",
       "      <td>8323</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>10705</td>\n",
       "      <td>2453</td>\n",
       "      <td>1317</td>\n",
       "      <td>95</td>\n",
       "      <td>99</td>\n",
       "      <td>5217</td>\n",
       "      <td>83</td>\n",
       "      <td>19840</td>\n",
       "      <td>6510</td>\n",
       "      <td>630</td>\n",
       "      <td>2115</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>5.8</td>\n",
       "      <td>49</td>\n",
       "      <td>40386</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>2989</td>\n",
       "      <td>1855</td>\n",
       "      <td>691</td>\n",
       "      <td>28</td>\n",
       "      <td>63</td>\n",
       "      <td>2988</td>\n",
       "      <td>1726</td>\n",
       "      <td>4990</td>\n",
       "      <td>3560</td>\n",
       "      <td>500</td>\n",
       "      <td>1250</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>18.1</td>\n",
       "      <td>28</td>\n",
       "      <td>4509</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>777 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Apps  Accept  Enroll  Top10perc  Top25perc  F.Undergrad  P.Undergrad  \\\n",
       "0     1660    1232     721         23         52         2885          537   \n",
       "1     2186    1924     512         16         29         2683         1227   \n",
       "2     1428    1097     336         22         50         1036           99   \n",
       "3      417     349     137         60         89          510           63   \n",
       "4      193     146      55         16         44          249          869   \n",
       "..     ...     ...     ...        ...        ...          ...          ...   \n",
       "772   2197    1515     543          4         26         3089         2029   \n",
       "773   1959    1805     695         24         47         2849         1107   \n",
       "774   2097    1915     695         34         61         2793          166   \n",
       "775  10705    2453    1317         95         99         5217           83   \n",
       "776   2989    1855     691         28         63         2988         1726   \n",
       "\n",
       "     Outstate  Room.Board  Books  Personal  PhD  Terminal  S.F.Ratio  \\\n",
       "0        7440        3300    450      2200   70        78       18.1   \n",
       "1       12280        6450    750      1500   29        30       12.2   \n",
       "2       11250        3750    400      1165   53        66       12.9   \n",
       "3       12960        5450    450       875   92        97        7.7   \n",
       "4        7560        4120    800      1500   76        72       11.9   \n",
       "..        ...         ...    ...       ...  ...       ...        ...   \n",
       "772      6797        3900    500      1200   60        60       21.0   \n",
       "773     11520        4960    600      1250   73        75       13.3   \n",
       "774      6900        4200    617       781   67        75       14.4   \n",
       "775     19840        6510    630      2115   96        96        5.8   \n",
       "776      4990        3560    500      1250   75        75       18.1   \n",
       "\n",
       "     perc.alumni  Expend  Grad.Rate  \n",
       "0             12    7041         60  \n",
       "1             16   10527         56  \n",
       "2             30    8735         54  \n",
       "3             37   19016         59  \n",
       "4              2   10922         15  \n",
       "..           ...     ...        ...  \n",
       "772           14    4469         40  \n",
       "773           31    9189         83  \n",
       "774           20    8323         49  \n",
       "775           49   40386         99  \n",
       "776           28    4509         99  \n",
       "\n",
       "[777 rows x 17 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:, 1:]\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that everything is clean, it's time to split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(kernel='linear', C = 1.0)\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n",
      "[[ 43   6]\n",
      " [  7 100]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87        49\n",
      "           1       0.94      0.93      0.94       107\n",
      "\n",
      "    accuracy                           0.92       156\n",
      "   macro avg       0.90      0.91      0.90       156\n",
      "weighted avg       0.92      0.92      0.92       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------\n",
    "\n",
    "# Preprocess the data using StandardScalar and fit the same model again.\n",
    "\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.46881819e-01, -3.21205453e-01, -6.35089011e-02, ...,\n",
       "        -8.67574189e-01, -5.01910084e-01, -3.18251941e-01],\n",
       "       [-2.10884040e-01, -3.87029908e-02, -2.88584214e-01, ...,\n",
       "        -5.44572203e-01,  1.66109850e-01, -5.51261842e-01],\n",
       "       [-4.06865631e-01, -3.76317928e-01, -4.78121319e-01, ...,\n",
       "         5.85934748e-01, -1.77289956e-01, -6.67766793e-01],\n",
       "       ...,\n",
       "       [-2.33895071e-01, -4.23771558e-02, -9.15087008e-02, ...,\n",
       "        -2.21570217e-01, -2.56241250e-01, -9.59029170e-01],\n",
       "       [ 1.99171118e+00,  1.77256262e-01,  5.78332661e-01, ...,\n",
       "         2.12019418e+00,  5.88797079e+00,  1.95359460e+00],\n",
       "       [-3.26765760e-03, -6.68715889e-02, -9.58163623e-02, ...,\n",
       "         4.24433755e-01, -9.87115613e-01,  1.95359460e+00]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "st_scale = StandardScaler()\n",
    "st_scale.fit(X)\n",
    "X = st_scale.transform(X)\n",
    "\n",
    "# great, now make sure that it worked...\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC(kernel='linear', C = 1.0)\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9230769230769231\n",
      "[[ 43   6]\n",
      " [  6 101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88        49\n",
      "           1       0.94      0.94      0.94       107\n",
      "\n",
      "    accuracy                           0.92       156\n",
      "   macro avg       0.91      0.91      0.91       156\n",
      "weighted avg       0.92      0.92      0.92       156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------\n",
    "\n",
    "# Use scikit-learn’s gridsearch to select the best hyper-parameter for a non-linear SVM\n",
    "\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refresh the data\n",
    "\n",
    "st_scale.fit(X)\n",
    "X = st_scale.transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now employ the non-linear SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC()\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time for Grid Search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\"C\" : [0.1, 1, 10, 100], \"gamma\" : [1, 0.1, 0.01, 0.001]}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] END .....................................C=0.1, gamma=1; total time=   0.0s\n",
      "[CV] END .....................................C=0.1, gamma=1; total time=   0.0s\n",
      "[CV] END .....................................C=0.1, gamma=1; total time=   0.0s\n",
      "[CV] END .....................................C=0.1, gamma=1; total time=   0.0s\n",
      "[CV] END .....................................C=0.1, gamma=1; total time=   0.0s\n",
      "[CV] END ...................................C=0.1, gamma=0.1; total time=   0.0s\n",
      "[CV] END ...................................C=0.1, gamma=0.1; total time=   0.0s\n",
      "[CV] END ...................................C=0.1, gamma=0.1; total time=   0.0s\n",
      "[CV] END ...................................C=0.1, gamma=0.1; total time=   0.0s\n",
      "[CV] END ...................................C=0.1, gamma=0.1; total time=   0.0s\n",
      "[CV] END ..................................C=0.1, gamma=0.01; total time=   0.0s\n",
      "[CV] END ..................................C=0.1, gamma=0.01; total time=   0.0s\n",
      "[CV] END ..................................C=0.1, gamma=0.01; total time=   0.0s\n",
      "[CV] END ..................................C=0.1, gamma=0.01; total time=   0.0s\n",
      "[CV] END ..................................C=0.1, gamma=0.01; total time=   0.0s\n",
      "[CV] END .................................C=0.1, gamma=0.001; total time=   0.0s\n",
      "[CV] END .................................C=0.1, gamma=0.001; total time=   0.0s\n",
      "[CV] END .................................C=0.1, gamma=0.001; total time=   0.0s\n",
      "[CV] END .................................C=0.1, gamma=0.001; total time=   0.0s\n",
      "[CV] END .................................C=0.1, gamma=0.001; total time=   0.0s\n",
      "[CV] END .......................................C=1, gamma=1; total time=   0.0s\n",
      "[CV] END .......................................C=1, gamma=1; total time=   0.0s\n",
      "[CV] END .......................................C=1, gamma=1; total time=   0.0s\n",
      "[CV] END .......................................C=1, gamma=1; total time=   0.0s\n",
      "[CV] END .......................................C=1, gamma=1; total time=   0.0s\n",
      "[CV] END .....................................C=1, gamma=0.1; total time=   0.0s\n",
      "[CV] END .....................................C=1, gamma=0.1; total time=   0.0s\n",
      "[CV] END .....................................C=1, gamma=0.1; total time=   0.0s\n",
      "[CV] END .....................................C=1, gamma=0.1; total time=   0.0s\n",
      "[CV] END .....................................C=1, gamma=0.1; total time=   0.0s\n",
      "[CV] END ....................................C=1, gamma=0.01; total time=   0.0s\n",
      "[CV] END ....................................C=1, gamma=0.01; total time=   0.0s\n",
      "[CV] END ....................................C=1, gamma=0.01; total time=   0.0s\n",
      "[CV] END ....................................C=1, gamma=0.01; total time=   0.0s\n",
      "[CV] END ....................................C=1, gamma=0.01; total time=   0.0s\n",
      "[CV] END ...................................C=1, gamma=0.001; total time=   0.0s\n",
      "[CV] END ...................................C=1, gamma=0.001; total time=   0.0s\n",
      "[CV] END ...................................C=1, gamma=0.001; total time=   0.0s\n",
      "[CV] END ...................................C=1, gamma=0.001; total time=   0.0s\n",
      "[CV] END ...................................C=1, gamma=0.001; total time=   0.0s\n",
      "[CV] END ......................................C=10, gamma=1; total time=   0.0s\n",
      "[CV] END ......................................C=10, gamma=1; total time=   0.0s\n",
      "[CV] END ......................................C=10, gamma=1; total time=   0.0s\n",
      "[CV] END ......................................C=10, gamma=1; total time=   0.0s\n",
      "[CV] END ......................................C=10, gamma=1; total time=   0.0s\n",
      "[CV] END ....................................C=10, gamma=0.1; total time=   0.0s\n",
      "[CV] END ....................................C=10, gamma=0.1; total time=   0.0s\n",
      "[CV] END ....................................C=10, gamma=0.1; total time=   0.0s\n",
      "[CV] END ....................................C=10, gamma=0.1; total time=   0.0s\n",
      "[CV] END ....................................C=10, gamma=0.1; total time=   0.0s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=   0.0s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=   0.0s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=   0.0s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=   0.0s\n",
      "[CV] END ...................................C=10, gamma=0.01; total time=   0.0s\n",
      "[CV] END ..................................C=10, gamma=0.001; total time=   0.0s\n",
      "[CV] END ..................................C=10, gamma=0.001; total time=   0.0s\n",
      "[CV] END ..................................C=10, gamma=0.001; total time=   0.0s\n",
      "[CV] END ..................................C=10, gamma=0.001; total time=   0.0s\n",
      "[CV] END ..................................C=10, gamma=0.001; total time=   0.0s\n",
      "[CV] END .....................................C=100, gamma=1; total time=   0.0s\n",
      "[CV] END .....................................C=100, gamma=1; total time=   0.0s\n",
      "[CV] END .....................................C=100, gamma=1; total time=   0.0s\n",
      "[CV] END .....................................C=100, gamma=1; total time=   0.0s\n",
      "[CV] END .....................................C=100, gamma=1; total time=   0.0s\n",
      "[CV] END ...................................C=100, gamma=0.1; total time=   0.0s\n",
      "[CV] END ...................................C=100, gamma=0.1; total time=   0.0s\n",
      "[CV] END ...................................C=100, gamma=0.1; total time=   0.0s\n",
      "[CV] END ...................................C=100, gamma=0.1; total time=   0.0s\n",
      "[CV] END ...................................C=100, gamma=0.1; total time=   0.0s\n",
      "[CV] END ..................................C=100, gamma=0.01; total time=   0.0s\n",
      "[CV] END ..................................C=100, gamma=0.01; total time=   0.0s\n",
      "[CV] END ..................................C=100, gamma=0.01; total time=   0.0s\n",
      "[CV] END ..................................C=100, gamma=0.01; total time=   0.0s\n",
      "[CV] END ..................................C=100, gamma=0.01; total time=   0.0s\n",
      "[CV] END .................................C=100, gamma=0.001; total time=   0.0s\n",
      "[CV] END .................................C=100, gamma=0.001; total time=   0.0s\n",
      "[CV] END .................................C=100, gamma=0.001; total time=   0.0s\n",
      "[CV] END .................................C=100, gamma=0.001; total time=   0.0s\n",
      "[CV] END .................................C=100, gamma=0.001; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9358974358974359\n",
      "[[ 67   8]\n",
      " [  7 152]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90        75\n",
      "           1       0.95      0.96      0.95       159\n",
      "\n",
      "    accuracy                           0.94       234\n",
      "   macro avg       0.93      0.92      0.93       234\n",
      "weighted avg       0.94      0.94      0.94       234\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, grid_predictions))\n",
    "print(confusion_matrix(y_test, grid_predictions))\n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------\n",
    "\n",
    "# **Conclusion:**\n",
    "\n",
    "# It seems like the non-linear Grid Search performed best."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c1a1d9d6f73acc8a0d16b6ff923022b649c9cb0ae43d43e5cd933eb191572bf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
